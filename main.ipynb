{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0931114e",
   "metadata": {},
   "source": [
    "Code for Urinary Bladder Cancer Screening with Electronic Noses Based on Few-Shot Contrastive Representation Learning and Open-Set Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea57d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from typing import Optional, Tuple\n",
    "from enum import IntEnum\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, \\\n",
    "    confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve\n",
    "import libmr\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "import os\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device is %s' % device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f4fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised contrastive learning (SuCL)\n",
    "\n",
    "class SuCL(nn.Module):\n",
    "    def __init__(self, temperature):\n",
    "        super(SuCL, self).__init__()\n",
    "        self.register_buffer(\"temperature\", torch.tensor(temperature))\n",
    "\n",
    "\n",
    "    def forward(self, emb_i, label):\n",
    "        representations = F.normalize(emb_i, dim=1)\n",
    "        n = representations.shape[0]\n",
    "        similarity_matrix = F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)\n",
    "        mask = torch.ones_like(similarity_matrix) * (label.expand(n, n).eq(label.expand(n, n).t()))\n",
    "        mask_no_sim = torch.ones_like(mask) - mask\n",
    "        mask_trace_0 = torch.ones(n, n) - torch.eye(n, n)\n",
    "        similarity_matrix = torch.exp(similarity_matrix / self.temperature)\n",
    "        similarity_matrix = similarity_matrix * mask_trace_0.to(device)\n",
    "        sim = mask * similarity_matrix\n",
    "        no_sim = similarity_matrix - sim\n",
    "        no_sim_sum = torch.sum(no_sim, dim=1)\n",
    "        no_sim_sum_expend = no_sim_sum.repeat(n, 1).T\n",
    "        sim_sum = sim + no_sim_sum_expend\n",
    "\n",
    "        loss = torch.div(sim, sim_sum)\n",
    "        loss = mask_no_sim + loss + torch.eye(n, n).to(device)\n",
    "        loss = -torch.log(loss)  \n",
    "        loss = torch.sum(torch.sum(loss, dim=1)) / (len(torch.nonzero(loss)))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c81a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deep residual neural network (ResNet)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1, shortcut=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv1d(inchannel, outchannel, 3, stride, 1, bias=False),   \n",
    "            nn.BatchNorm1d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(outchannel, outchannel, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm1d(outchannel)\n",
    "        )\n",
    "        self.right = shortcut\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        residual = x if self.right is None else self.right(x)\n",
    "        out += residual\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, blocks, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.model_name = 'resnet34'\n",
    "\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv1d(6, 64, 7, 2, 3, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(3, 2, 1))\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 64, blocks[0])\n",
    "        self.layer2 = self._make_layer(64, 128, blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, blocks[3], stride=2)\n",
    "\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "\n",
    "    def _make_layer(self, inchannel, outchannel, block_num, stride=1):\n",
    "        \n",
    "        shortcut = nn.Sequential(\n",
    "            nn.Conv1d(inchannel, outchannel, 1, stride, bias=False),\n",
    "            nn.BatchNorm1d(outchannel),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(inchannel, outchannel, stride, shortcut))\n",
    "\n",
    "        for i in range(1, block_num):\n",
    "            layers.append(ResidualBlock(outchannel, outchannel))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.pre(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = nn.AdaptiveAvgPool1d(1)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x), x\n",
    "    \n",
    "\n",
    "def Resnet18(num_class=10):\n",
    "    return ResNet([2, 2, 2, 2], num_class)\n",
    "\n",
    "\n",
    "def Resnet34(num_class=10):\n",
    "    return ResNet([3, 4, 6, 3], num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datas import load_data\n",
    "\n",
    "LOADPATH = \"./data/\"\n",
    "picked_sensors = [4, 6, 7, 9, 11, 12] # picked 6 sensors\n",
    "# origin sample size: (n, 65, 13)\n",
    "# sample size: (n, 65, 6)\n",
    "# label size: (n,)\n",
    "train_dataset, val_dataset, test_dataset, open_test_dataset, weibull_dataset = load_data(LOADPATH, picked_sensors)\n",
    "\n",
    "Batch_size = 128\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=Batch_size, shuffle=True)\n",
    "valid_loader = Data.DataLoader(dataset=val_dataset, batch_size=Batch_size, shuffle=False)\n",
    "test_loader = Data.DataLoader(dataset=test_dataset, batch_size=Batch_size, shuffle=False)\n",
    "open_test_loader = Data.DataLoader(dataset=open_test_dataset, batch_size=1, shuffle=False)\n",
    "weibull_loader = Data.DataLoader(dataset=weibull_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"created data loader successfully...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def get_confusion_matrix(trues, preds):\n",
    "    labels = []\n",
    "    for i in range(len(set(labels))):\n",
    "        labels.append(i)\n",
    "    conf_matrix = confusion_matrix(trues, preds)\n",
    "    return conf_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix):\n",
    "    plt.imshow(conf_matrix.T, cmap=plt.cm.Greens)\n",
    "    indices = range(conf_matrix.shape[0])\n",
    "    labels = []\n",
    "    for i in range(6):\n",
    "        labels.append(i)\n",
    "\n",
    "    plt.xticks(indices, labels)\n",
    "    plt.yticks(indices, labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('y_true')\n",
    "    plt.ylabel('y_pred')\n",
    "   \n",
    "    for first_index in range(conf_matrix.shape[0]):\n",
    "        for second_index in range(conf_matrix.shape[1]):\n",
    "            plt.text(first_index, second_index, conf_matrix[first_index, second_index])\n",
    "    plt.savefig('heatmap_confusion_matrix_18.jpg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_open(conf_matrix):\n",
    "    plt.imshow(conf_matrix.T, cmap=plt.cm.Greens)\n",
    "    indices = range(conf_matrix.shape[0])\n",
    "    labels = []\n",
    "    for i in range(len(conf_matrix)):\n",
    "        labels.append(i)\n",
    "\n",
    "    plt.xticks(indices, labels)\n",
    "    plt.yticks(indices, labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('y_true')\n",
    "    plt.ylabel('y_pred')\n",
    "    \n",
    "    for first_index in range(conf_matrix.shape[0]):\n",
    "        for second_index in range(conf_matrix.shape[1]):\n",
    "            plt.text(first_index, second_index, conf_matrix[first_index, second_index])\n",
    "    plt.savefig('heatmap_confusion_matrix_18_open.jpg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = False\n",
    "load_model = True  \n",
    "load_model_epoch = 700 \n",
    "save_model = True  \n",
    "save_each_epoch = 100 \n",
    "EPOCH = 0\n",
    "\n",
    "# hyperparameters\n",
    "w_ce = 1\n",
    "w_cl = 0.5\n",
    "\n",
    "if training:\n",
    "    model = Resnet34(num_class=6).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "    loss_function = nn.CrossEntropyLoss()  \n",
    "    scl_loss = SuCL(temperature=0.7)\n",
    "\n",
    "    if load_model:\n",
    "        checkpoint = torch.load('./checkpoints/model_checkpoint_' + str(load_model_epoch) + '.tar')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        load_epoch = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        print('load model over ... ')\n",
    "        start_epoch = load_epoch + 1\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    print('start training ... ')\n",
    "    hist_loss = np.zeros(EPOCH)\n",
    "    hist_loss_val = np.zeros(EPOCH)\n",
    "    hist_loss_test = np.zeros(EPOCH)\n",
    "    model.train()\n",
    "\n",
    "    train_dict = {}\n",
    "    valid_dict = {}\n",
    "    test_dict = {}\n",
    "\n",
    "    # test_loader = None\n",
    "    for epoch in range(start_epoch, start_epoch + EPOCH):\n",
    "        tol_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_trues = []\n",
    "        for x, y in train_loader:\n",
    "            batch_x = Variable(x)\n",
    "            batch_y = Variable(y)\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.long().to(device)\n",
    "            output, outscl = model(batch_x)\n",
    "            \n",
    "            loss_ce = loss_function(output, batch_y.squeeze(dim=1))\n",
    "            loss_cl = scl_loss(outscl, batch_y.squeeze(dim=1))\n",
    "            loss = w_ce * loss_ce + w_cl * loss_cl\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tol_loss += loss.item()\n",
    "            train_outputs = output.argmax(dim=1)\n",
    "\n",
    "            train_preds.extend(train_outputs.detach().cpu().numpy())\n",
    "            train_trues.extend(batch_y.detach().cpu().numpy())\n",
    "\n",
    "        sklearn_accuracy = accuracy_score(train_trues, train_preds)\n",
    "        sklearn_precision = precision_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_recall = recall_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(train_trues, train_preds, average='micro')\n",
    "        hist_loss[epoch - start_epoch] = tol_loss\n",
    "        print(\n",
    "            \"[sklearn_metrics] Epoch:{} loss:{:.4f} accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(\n",
    "                epoch,\n",
    "                tol_loss,\n",
    "                sklearn_accuracy,\n",
    "                sklearn_precision,\n",
    "                sklearn_recall,\n",
    "                sklearn_f1))\n",
    "\n",
    "        model.eval()\n",
    "        val_pres = []\n",
    "        val_trues = []\n",
    "        tol_val_loss = 0\n",
    "        for val_x, val_y in valid_loader:\n",
    "            # Propagate input\n",
    "            val_netout, outscl = model(val_x.to(device))\n",
    "            val_y = val_y.long().to(device)\n",
    "\n",
    "            # Comupte loss\n",
    "            loss_ce = loss_function(val_netout, val_y.squeeze(dim=1))\n",
    "            loss_cl = scl_loss(outscl, val_y.squeeze(dim=1))\n",
    "            val_loss = w_ce * loss_ce + w_cl * loss_cl\n",
    "\n",
    "            tol_val_loss += val_loss.data\n",
    "            val_outputs = val_netout.argmax(dim=1)\n",
    "\n",
    "            val_pres.extend(val_outputs.detach().cpu().numpy())\n",
    "            val_trues.extend(val_y.detach().cpu().numpy())\n",
    "\n",
    "        sklearn_val_accuracy = accuracy_score(val_trues, val_pres)\n",
    "        sklearn_val_precision = precision_score(val_trues, val_pres, average='micro')\n",
    "        sklearn_val_recall = recall_score(val_trues, val_pres, average='micro')\n",
    "        sklearn_val_f1 = f1_score(val_trues, val_pres, average='micro')\n",
    "\n",
    "        hist_loss_val[epoch - start_epoch] = tol_val_loss\n",
    "        print(\n",
    "            \"[sklearn_val_metrics] Epoch:{} val_loss:{:.4f} val_accuracy:{:.4f} val_precision:{:.4f} val_recall:{:.4f} val_f1:{:.4f}\"\n",
    "                .format(epoch, tol_val_loss, sklearn_val_accuracy, sklearn_val_precision, sklearn_val_recall,\n",
    "                        sklearn_val_f1))\n",
    "\n",
    "        # close set test\n",
    "        model.eval()\n",
    "        test_pres = []\n",
    "        test_trues = []\n",
    "        scores_pred = []\n",
    "        tol_test_loss = 0\n",
    "        test = True\n",
    "        if test:\n",
    "            for test_x, test_y in test_loader:\n",
    "                # Propagate input\n",
    "                test_netout, outscl = model(test_x.to(device))\n",
    "                test_y = test_y.long().to(device)\n",
    "                scores_pred.append(F.softmax(test_netout))\n",
    "                # Comupte loss\n",
    "                loss_ce = loss_function(test_netout, test_y.squeeze(dim=1))\n",
    "                loss_cl = scl_loss(outscl, test_y.squeeze(dim=1))\n",
    "                test_loss = w_ce * loss_ce + w_cl * loss_cl\n",
    "                tol_test_loss += test_loss.data\n",
    "                test_outputs = test_netout.argmax(dim=1)\n",
    "                test_pres.extend(test_outputs.detach().cpu().numpy())\n",
    "                test_trues.extend(test_y.detach().cpu().numpy())\n",
    "\n",
    "            sklearn_test_accuracy = accuracy_score(test_trues, test_pres)\n",
    "            sklearn_test_precision = precision_score(test_trues, test_pres, average='micro')\n",
    "            sklearn_test_recall = recall_score(test_trues, test_pres, average='micro')\n",
    "            sklearn_test_f1 = f1_score(test_trues, test_pres, average='micro')\n",
    "            hist_loss_test[epoch - start_epoch] = tol_test_loss\n",
    "            print(\n",
    "                \"[sklearn_closeset_test_metrics] Epoch:{} test_loss:{:.4f} test_accuracy:{:.4f} test_precision:{:.4f} test_recall:{:.4f} test_f1:{:.4f}\"\n",
    "                    .format(epoch, tol_test_loss, sklearn_test_accuracy, sklearn_test_precision, sklearn_test_recall,\n",
    "                            sklearn_test_f1))\n",
    "            \n",
    "            print(\"print confusuionMatrix of closeSet classification:\\n\")\n",
    "            conf_matrix = get_confusion_matrix(train_trues, train_preds)\n",
    "            plot_confusion_matrix(conf_matrix)\n",
    "            model.train()\n",
    "            \n",
    "            test_trues_one = label_binarize(test_trues, classes=[0, 1, 2, 3, 4, 5])\n",
    "        if epoch % save_each_epoch == 0 and save_model:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': tol_loss\n",
    "            }, './checkpoints/model_checkpoint_' + str(epoch) + '.tar'  \n",
    "            )\n",
    "    plt.plot(hist_loss, 'o-', label='train')\n",
    "    plt.plot(hist_loss_val, 'o-', label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss_18.jpg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d654c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open set test\n",
    "testing = True\n",
    "start_ind = 0\n",
    "ts_percent = 0.1\n",
    "ts_limit = 15\n",
    "\n",
    "# decide checkpoints which need to test\n",
    "start_ckeckpoint = 700\n",
    "end_checkpoint = 701\n",
    "checkpoint_step = 100\n",
    "\n",
    "if testing:\n",
    "    model = Resnet34(num_class=6).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    result = []\n",
    "    for cp in range(start_ckeckpoint, end_checkpoint, checkpoint_step):\n",
    "        \n",
    "        checkpoint = torch.load(f'./checkpoints/model_checkpoint_{cp}.tar')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        class_v = [[], [], [], [], [], []]\n",
    "        \n",
    "        for x, y in weibull_loader:\n",
    "            batch_x = Variable(x)  \n",
    "            batch_y = Variable(y)\n",
    "            batch_x = batch_x.float().to(device) \n",
    "            batch_y = batch_y.long().to(device)\n",
    "            output, outscl = model(batch_x)\n",
    "            score = output.argmax(axis=1).to('cpu')\n",
    "            yy = y.reshape(-1).int()\n",
    "            b = score.eq(yy)\n",
    "            \n",
    "            if b[0]:\n",
    "                class_v[int(yy[0].item())].append(output)\n",
    "        center = []\n",
    "        mr_all = []\n",
    "        \n",
    "        for i in range(6):\n",
    "            assert (len(class_v[i]) != 0)\n",
    "            class_va = torch.cat(class_v[i])\n",
    "            class_mean = torch.mean(class_va, dim=0)\n",
    "            center.append(class_mean)\n",
    "            d_s = torch.pow(class_va - class_mean, 2).sum(dim=1)\n",
    "            out = torch.sqrt(d_s)\n",
    "            out, indx = torch.sort(out)\n",
    "            mr = libmr.MR()\n",
    "            tailSize = int(out.shape[0] * ts_percent)\n",
    "            tailSize = max(tailSize, ts_limit)\n",
    "            mr.fit_high(out, tailSize)\n",
    "            mr_all.append(mr)\n",
    "\n",
    "        all_score = []\n",
    "        test_pres = []\n",
    "        test_trues = []\n",
    "        scores_pred = []\n",
    "        pred_list = []\n",
    "\n",
    "        for x, y in open_test_loader:\n",
    "            batch_x = Variable(x)  \n",
    "            batch_x = batch_x.float().to(device)  \n",
    "            batch_y = int(y.item()) \n",
    "            output, outscl = model(batch_x)\n",
    "            scores = []\n",
    "            unknownList = []\n",
    "            \n",
    "            for ii, cent in enumerate(center):\n",
    "                d_s = torch.pow(output - cent, 2).sum(dim=1)\n",
    "                out = torch.sqrt(d_s)\n",
    "                score_ = mr_all[ii].w_score(out)\n",
    "                modified_score = output[0, ii] * (1 - score_)\n",
    "                scores.append(modified_score)\n",
    "                unkown = output[0, ii] - modified_score\n",
    "                unknownList.append(unkown)\n",
    "            \n",
    "            unkown_score = sum(unknownList)\n",
    "            scores.append(unkown_score)\n",
    "            scores = torch.tensor(scores)\n",
    "            scores_pred.append(F.softmax(scores))\n",
    "            scores_ = F.softmax(scores)\n",
    "            max_s = torch.max(scores_)\n",
    "            thresd = 0.8  \n",
    "\n",
    "            if max_s > thresd:\n",
    "                test_outputs = scores.argmax()\n",
    "                test_pres.append(test_outputs.item())\n",
    "            else:\n",
    "                test_pres.append(6)\n",
    "            \n",
    "            scores_pred.append(F.softmax(scores))\n",
    "            test_trues.append(batch_y)\n",
    "            pred_score = scores.numpy()\n",
    "            pred_prob = scores_.numpy()\n",
    "            pred_result = np.append(pred_score, np.append(pred_prob, batch_y))\n",
    "            pred_list.append(pred_result)\n",
    "        \n",
    "        pred_list = np.array(pred_list)\n",
    "        df = pd.DataFrame(pred_list)\n",
    "        df.to_csv('OSCresult.csv', index=False, header=False)\n",
    "        print(\"saved OSC result successfully... \")\n",
    "        test_trues = np.array(test_trues)\n",
    "        test_pres = np.array(test_pres)\n",
    "        test_trues = (test_trues == 5).astype(int)\n",
    "        test_pres = (test_pres == 5).astype(int)\n",
    "        conf_matrix = get_confusion_matrix(test_trues, test_pres)\n",
    "        precision = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])\n",
    "        recall = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        fpr = conf_matrix[1, 0] / (conf_matrix[0, 0] + conf_matrix[1, 0])\n",
    "        \n",
    "        print(f'f1: {f1 :.4f}, precision: {precision :.4f}, recall: {recall :.4f}, fpr: {fpr :.4f}')\n",
    "        conf_matrix = get_confusion_matrix(test_trues, test_pres)\n",
    "        plot_confusion_matrix_open(conf_matrix)\n",
    "        result.append((f1, precision, recall, fpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
